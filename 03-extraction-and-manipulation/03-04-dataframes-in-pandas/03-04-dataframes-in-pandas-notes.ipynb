{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Course Updates 10/30/2019</span>\n",
    "\n",
    "## Updated schedule through the rest of the semester\n",
    "\n",
    "|  Wk   |  M    |  W     | Topic   | Notebooks |\n",
    "| :---: | :---: | :----: | :------ | :----- |\n",
    "|  8  |  10/21  | 23  | **Numpy:** Data Abstraction, **Numpy:** Multi-dimensional arrays,  | Midterm, 03-01, 03-02 |\n",
    "|  9  |  28  | 30  | **Numpy:** Reading into multi-dimensional arrays, **Pandas:** Dataframes and reading into them;  Merging and matching Dataframes| 03-03, 03-04, 03-05 |\n",
    "|  10  |  11/4  | 6  | **Pandas:** , Series and Views; Wrap Up Unit 3| 03-06, 03-07 |\n",
    "|  11 |  11  | 13   | Classification and Clustering, **Case Study:** Iris Data Set | 04-02, 04-03  |\n",
    "|   |    |    | Notebooks under development&dagger;  | <del>04-04, 04-06, 04-07</del>  |\n",
    "|  12 |  18  | 20  | **Case Study:** [World Happiness Report](https://worldhappiness.report/ed/2019/)  | 04-04, 05-01 |\n",
    "|  13 |  25   | &mdash;  | [Geopandas](http://geopandas.org/), **Case Study:** World Happiness Map | 05-03 |\n",
    "|  14 |  12/2 | 4 |  **Case Study:** Twitter Sentiment Analysis | 05-04 |\n",
    "|  16 |  | 12/13 | **(Take Home) Final Exam**  |\n",
    "\n",
    "&dagger; We will not be covering these notebooks this semester. Feel free to peruse them if interested.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## JupyterHub Merging Behavior\n",
    "\n",
    "According to the [documentation](https://jupyterhub.github.io/nbgitpuller/topic/automatic-merging.html#topic-automatic-merging), it shouldn't be necessary for the instructor to create new versions of notebooks.\n",
    "\n",
    "> If the student has deleted a file locally, but the file is still present in the remote repo, the file from the remote repo is pulled into the student’s directory. This enables the use case where a student wants to ‘start over’ a file after having made many changes to it. They can simply delete the file, click the nbgitpuller link again, and get a fresh copy.\n",
    "\n",
    "You just need to delete your local version in order to get the latest. Let us try it with the `03-04-dataframes-in-pandas` notebook. Load the notebook by clicking on the Canvas link. It may bring an old copy of the notebook (if you had worked on it before) or a fresh copy (if you hadn't).\n",
    "\n",
    "1. Make an innocuous change to the notebook (put your name into a **`code`** cell, for example) and Save and Checkpoint it. \n",
    "2. To avoid losing your work, use **File >> Make a Copy...** to create a backup. \n",
    "3. Delete the notebook by going up a directory level. In other words, if your URL is `.../a/b/c.ipynb`, go to `.../a/b/` in a different tab, select the `.../a/b/c.ipynb` file and delete it.\n",
    "4. Click on the Canvas link again. _The changes you had made in step 1 should have disappeared, proving that deleting the file and coming back in through Canvas loads a fresh copy of the notebook!_\n",
    "5. Delete the copy you made in step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Dataframes in Pandas</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Numpy\n",
    "\n",
    "* Numpy is limited by the basic limit of having to have the same type for every element of an `ndarray`. That is its strength and its weakness. <img align=\"right\" style=\"padding-left:10px; height: 65%; width: 65%\" src=\"Addenda/figures/numpy-arrays.png\" >\n",
    "    * Numpy's ability to deal with multidimensional data is a major advantage when doing scientific calculations using vectors, matrices and tensors.\n",
    "    * The exercise in 03-03-data-ingest revealed this limitation of Numpy when we couldn't read a rectangular structure with dissimilar data types into an `ndarray`. See SciPy [Structured Arrays and Structured Datatypes](https://docs.scipy.org/doc/numpy/user/basics.rec.html) for more details.\n",
    "    * Metadata information &mdash; what each row or column represents must be maintained outside of the `ndarray`\n",
    "* Columns in a typical spreadsheet can each be of a different type. \n",
    "* Thus, Numpy does not correctly express spreadsheets. \n",
    "* The `DataFrame` concept completely embodies the concept of a spreadsheet with multiple column types. \n",
    "\n",
    "These workbooks are based upon [pandas in 10 minutes](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) and subsequent detailed tutorials.\n",
    "\n",
    "# Pandas and numpy\n",
    "* Pandas is -- in fact -- based upon `numpy` and `numpy.ndarray` concepts. \n",
    "* The convenience of Pandas comes from being higher-level. \n",
    "* In a detailed analysis, `numpy.ndarray` is often still required, e.g., for TensorFlow and related tools. \n",
    "* Thus, one has to understand \"both levels of abstraction.\"\n",
    "\n",
    "# Pandas vs. Numpy\n",
    "\n",
    "| numpy | pandas |\n",
    "|-------|--------|\n",
    "| Strength is multidimensional arrays and tensors | Strength is spreadsheets and time series |\n",
    "| Assumes integer axes | Allows axes based upon timestamp and other indexes |\n",
    "| Assumes homogeneous types | Allows heterogeneous column types |\n",
    "| Row queries are complex | Rpw queries are simple |\n",
    "| Rudimentary csv handling | Advanced csv handling includes all special cases | \n",
    " \n",
    "# Why most people use Pandas\n",
    "* Most data is in spreadsheets. \n",
    "* Unlike numpy, pandas makes reading spreadsheets trivial. \n",
    "\n",
    "# My advice \n",
    "* if your data is csv, then *read it into pandas and then reformat it into the appropriate numpy objects as needed.* \n",
    "Consider: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%more data1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading1</th>\n",
       "      <th>heading2</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>This is, of course, problematic in numpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>This is, too</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   heading1  heading2                                  comments\n",
       "0         1         2  This is, of course, problematic in numpy\n",
       "1         3         4                              This is, too"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv('data1.csv')\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "* Pandas is tuned to read MS Excel spreadsheets. \n",
    "* You can thus stop worrying about commas in strings. \n",
    "* Printouts are made pretty via correct pretty-printing calls. \n",
    "* Row number/index is listed to left. \n",
    "\n",
    "# What happened to `numpy`? \n",
    "* `data1` is a `DataFrame`. \n",
    "* Each of the columns are represented in `numpy`\n",
    "\n",
    "Consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    3\n",
       "Name: heading1, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['heading1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    3\n",
       "Name: heading1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.heading1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['heading1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data1.heading1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Numpy is still underneath!*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The reality of higher-level abstractions\n",
    "* Do one thing well. \n",
    "* Are relatively poor at doing other things. \n",
    "\n",
    "# Pandas is\n",
    "* excellent at parsing spreadsheets. \n",
    "* relatively poor at numerical operations, at which `numpy` excels. \n",
    "* Absolutely horrible at tensors. My advice is simply *don't!* Use `numpy` instead. \n",
    "\n",
    "# Pandas joys\n",
    "Compared to `numpy`\n",
    "* Columns are accessed by name. \n",
    "* Everything prints prettily. \n",
    "* Row selection is intuitive.\n",
    "\n",
    "Consider: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[data1.heading1 > 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['sum'] = data1.heading1 + data1.heading2\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['approved'] = True\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "* Can access columns as if they are dictionaries. \n",
    "* Can access columns as if they are class members. \n",
    "* Can do column arithmetic. Result is a new column. \n",
    "* Can set a new column to the same value for all rows. \n",
    "* Can add columns to the `DataFrame` dynamically by using a new keyword for each new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[data1.heading1 > 2, 'heading2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[data1.heading1 > 2, 'heading2'] = 200\n",
    "data1[data1.heading1 > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whoa there! \n",
    "\n",
    "* What just happened? \n",
    "* You might recall that one of the major pains in `numpy` is that row data is immutable. \n",
    "* Here we managed to set a row and column based upon conditions upon all rows and columns. \n",
    "* `data1.loc[<row selector>, <column selector>] = <value>`\n",
    "* This is difficult to understand, but really powerful. \n",
    "* It's also not all-powerful, and what it can't do is important. \n",
    "\n",
    "# A tale of Lvalues and Rvalues \n",
    "* At its core, Pandas very heavily uses the hacks available in Python classes. \n",
    "* These allow it to control which expressions are Lvalues and which are Rvalues. \n",
    "* An *Lvalue* is anything that can be on the left of the = sign in an assignment. \n",
    "* An *Rvalue* can be on the right hand side of the = sign in an assignment. \n",
    "* For the most part, *Lvalues are Rvalues*, but not vice-versa. \n",
    "* But, in Pandas, there is an active tension between \n",
    "    \n",
    "    * Selecting data and \n",
    "    * Setting data. \n",
    "\n",
    "* That plays out by defining *different dyntaxes for setting and selection.*\n",
    "\n",
    "# What this means in practice is that:\n",
    "* One should be wary of placing expressions like df[..] on the left-hand side of the =, \n",
    "* because *there is a distinct syntax df.loc[...] that is designed for that!*\n",
    "\n",
    "# An aside: how we control Lvalues and Rvalues in Python\n",
    "* Python classes allow one to define methods that are different for whether the object is on the left-hand or right-hand side of the = sign. \n",
    "* Here is a simple demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo(): \n",
    "    items = []\n",
    "    def __getitem__(self, index): \n",
    "        print(\"I'm getting the the value at index {}\".format(index))\n",
    "        return self.items[index]\n",
    "    def __setitem__(self, index, value): \n",
    "        print(\"I'm setting item at index {} to {}\".format(index, value))\n",
    "        while (len(self.items) < index+1): \n",
    "            self.items.append(None)\n",
    "        self.items[index] = value\n",
    "\n",
    "f = Foo()\n",
    "f[4] = 'yo'  # f,__setitem__(4, 'yo')\n",
    "print(f.items)\n",
    "f[4]  # f.__getitem__(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This insane little class\n",
    "* implements a *self-extending list*. \n",
    "* values that are not defined are set to `None`.\n",
    "* Without this intervention, if `f` were a regular list, this code would result in a runtime error. \n",
    "\n",
    "# The Lvalue/Rvalue minefield\n",
    "* When learning Pandas and specifically `DataFrame`s, it's really difficult to keep straight what can be on the left-hand-side of the = sign in an assignment. \n",
    "* This can be a coding minefield, where assignment statements can \"blow up\" when you least expect them to do so. \n",
    "* Some things that look like Lvalues actually are.\n",
    "    * Assigning a list of values to a whole column. \n",
    "* Some things that look like Lvalues are not, e.g., \n",
    "    * Assigning a value to part of a column. \n",
    "\n",
    "# Let's put this into practice.  \n",
    "\n",
    "First, let's load some interesting data into a DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "towns = pd.read_csv('2010_Population_By_Town.csv')\n",
    "print(\"First 10 rows are:\")\n",
    "towns.head()  # First 5 rows. Remove qualifier to see all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(source: US census, state of Conn, data.gov) \n",
    "\n",
    "1. Write an expression for rows for towns with population above 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write an expression for all towns whose name starts with 'C'. Hint: use >= 'C', < 'D' to select. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer: \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write code to create a new column `Cool` and mark `Clinton` and `Wolcott` as `Cool` by setting their `Cool` columns to `True` and everyone else's to `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to test your answer\n",
    "towns[towns.Cool == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. List all towns with at least 14 characters in their names. Hint: you can apply `.str.len()` to a column to get its length as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following additional table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax = pd.read_csv('2012_Retail_Sales_By_Town_ALL_NAICS.csv', engine='python', skipfooter=8)\n",
    "print(\"First 5 rows of tax are:\")\n",
    "tax.head()  # first 5 rows; you can remove the qualifier to see the whole table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compute \"Tax per capita\" as a new column by dividing \"Total Tax Due\" by \"Number of Taxpayers\". There is whitespace at the end of the label for \"Total Tax Due\"! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the following before beginning: \n",
    "list(tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to test your answer: \n",
    "tax.head()  # first 5 rows of solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. List the towns in which the tax per capita is larger than $80,000 per entity (Gasp! This is sales tax! Entities can be businesses, though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer:\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
