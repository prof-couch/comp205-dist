{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "* You're probably aware of some parametric prediction methods, e.g., linear regression.  \n",
    "* Let's study a non-parametric prediction method. \n",
    "* The goal of this method: classify something into one of a discrete number of types. \n",
    "* This is also known as 'supervised learning'. \n",
    "\n",
    "# Scikit-Learn\n",
    "\n",
    "* Scikit-Learn is a major machine learning library that includes many reference data sets. \n",
    "* Initial release: June 2007, predates `pandas` but not by much! (Scikit-Learn and `pandas` solved different set of problems so they could simply coexisted for a long time)\n",
    "* It has its own formats. \n",
    "* It's important to know how to translate to other formats to accomplish tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"padding-left:10px; height: 24%; width: 24%;\" src=\"figures/iris_with_labels.jpg\">\n",
    "\n",
    "# The Iris Dataset\n",
    "\n",
    "* There is one dataset that is so well-known that it bears mentioning in any context. \n",
    "* The *iris dataset* consists of a multidimensional array of iris characteristics used in determining species. \n",
    "* Let's explore this dataset and see if we can understand it. \n",
    "* More information on the iris dataset is available at the [Scikit-Learn website](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html).\n",
    "* Scikit-Learn also provides a [Jupyter notebook](plot_iris_dataset.ipynb) included here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a special-purpose format. \n",
    "* A class\n",
    "* Implemented as a dictionary. \n",
    "* Intended for testing machine-learning algorithms. \n",
    "* With fields that make sense for that task.\n",
    "* Most entries are arrays in `numpy` format. \n",
    "\n",
    "Let's find out a bit about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important fields in the iris dataset\n",
    "* `iris.data`: a set of feature vectors describing different plants. \n",
    "* `iris.target`: the kind of plant\n",
    "* `iris.feature_names`: the names of columns\n",
    "* `iris.target_names`: the English names of the kinds. \n",
    "\n",
    "# The classification problem\n",
    "* Given what we know about a thing (`iris.data`) \n",
    "* What species is it (`iris.target`)? \n",
    "\n",
    "# How we approach classification: \n",
    "* Take all data into account. \n",
    "* Think of the data as a function from `data` to `target`.\n",
    "* Approximate that function. \n",
    "\n",
    "# Then, if there is a new kind of iris, \n",
    "* Use the function to predict what species it is. \n",
    "\n",
    "# Let's run the demo provided by scikit-learn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Declare a KNN classifier of a given complexity. The number of neighbors determines runtime.\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# create a map between data and target. \n",
    "knn.fit(iris['data'], iris['target'])\n",
    "\n",
    "# Provide data whose class labels are to be predicted\n",
    "X = [\n",
    "    [5.9, 1.0, 5.1, 1.8],\n",
    "    [3.4, 2.0, 1.1, 4.8],\n",
    "]\n",
    "\n",
    "# Prints the data provided\n",
    "print(X)\n",
    "\n",
    "# Store predicted class labels of X\n",
    "prediction = knn.predict(X)\n",
    "\n",
    "# Prints the predicted class labels of X\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This, according to the predictor, they're both species 1 of 0-2. \n",
    "\n",
    "* Writing such a predictor is a complex task that we study in COMP 135. \n",
    "* You can read up on it here: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "For now, suffice it to say that from enough measurements, one can form a prediction \n",
    "from the instances that have been observed so far. This prediction can be accurate or inaccurate \n",
    "based upon the prediction method. \n",
    "\n",
    "# From whence comes accuracy\n",
    "* You would be right to be suspicious of what I just did. \n",
    "* I didn't tell you anything at all about the prediction method. It is an \"oracle\". \n",
    "* How do we know that this worked? \n",
    "\n",
    "# Cross-validation\n",
    "* Cross-validation is a standard technique in machine learning for testing classifiers. \n",
    "* Separate all feature data into 'training' and 'testing' subsets. \n",
    "* Train on the training subset. \n",
    "* Test on the testing subset. \n",
    "* See if you get the correct answers.\n",
    "\n",
    "# Let's do this. I'll help.\n",
    "* This is a different kind of exercise. \n",
    "* This is a real cross-validation using random data. \n",
    "* There is no one \"correct\" answer. \n",
    "* I can check your answers for sanity but not for correctness. \n",
    "\n",
    "First let's select rows of the data to use as training and testing data. This recipe selects them randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "selections = list(range(len(iris.data)))\n",
    "random.shuffle(selections)\n",
    "training_selections = selections[:130]\n",
    "testing_selections = selections[130:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What this does\n",
    "* `random.shuffle` scrambles the numbers between 0 and 149. \n",
    "* `training_selections` is a list of the array offsets for a training set. \n",
    "* `testing_selections` is a list of the array offsets for a testing set. \n",
    "* These are disjoint lists with no elements in common. \n",
    "* These represent a random sampling of the data in the iris database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('Classification.ok')\n",
    "ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an `array` `training_features` that consists of the rows that match `training_selections`. Look up how to do it. Hint: `iris.data` is an `array`. Use row selection for `np.array`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your answer:\n",
    "training_features = iris.data[training_selections]\n",
    "training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q01')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an `array` `training_targets` that consists of the targets corresponding to the selected training rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your answer\n",
    "training_targets = iris.target[training_selections]\n",
    "training_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q02')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the pattern above, train a kNN on the training data. Start with a new one `knn2` and just train on this. Hint: You need the data from parts 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "# Declare a KNN classifier of a given complexity. The number of neighbors determines runtime.\n",
    "import numpy as np\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# create a map between data and target. \n",
    "knn2.fit(training_features, training_targets)\n",
    "knn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Put the test data into an `array` `testing_features`, repeating what you did for training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "testing_features = iris.data[testing_selections]\n",
    "testing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q04')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the predictor as above, but on the array `testing_features`. Put the result into `test_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "test_results = knn.predict(testing_features)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q05')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compute the expected outcomes and put them into the `array` `expected_results`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "expected_results = iris.target[testing_selections]\n",
    "expected_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q06')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Count the number of identical answers between test_results and expected results and place the result into `correct_answers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "correct_answers = (test_results == expected_results).sum()\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An afterword on cross-validation\n",
    "* If you got a perfect result, you're lucky. \n",
    "* Classification algorithms aren't perfect. \n",
    "* You can run it again to get an imperfect result. \n",
    "* Running the cross-validation multiple times gives one an idea of how accurate the classifier will be. \n",
    "* There are no \"correct\" answers to this. You just ran a random trial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you are done with this notebook, \n",
    "\n",
    "* Save and checkpoint. \n",
    "* Ensure that the name of this file is precisely `04-02-classification.ipynb`. \n",
    "* Save and checkpoint the notebook. \n",
    "\n",
    "\n",
    "* If your Jupyter installation can download the notebook as a PDF,\n",
    "    * (File >> Download as >> PDF via LaTeX (.pdf)), \n",
    "    * Rename the downloaded file to `<loginid>-04-02-classification.pdf`. In other words, my filename would be `jsingh11-04-02-classification.pdf`.\n",
    "    * Submit the file `<loginid>-04-02-classification.pdf` to Canvas.\n",
    "* Otherwise \n",
    "    * (File >> Download as >> Notebook (.ipynb)). In other words, my filename would be `jsingh11-04-02-classification.ipynb`.\n",
    "    * Rename the downloaded file to `<loginid>-04-02-classification.ipynb`,\n",
    "    * Submit the file `<loginid>-04-02-classification.ipynb` to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
