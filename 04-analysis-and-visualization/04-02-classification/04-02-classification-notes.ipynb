{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Course Plan 11/6/2019</span>\n",
    "## <span style=\"color:blue\">(Updated 11/8/2019)</span>\n",
    "\n",
    "## Updated schedule through the rest of the semester\n",
    "\n",
    "|  Wk   |  M    |  W     | Topic   | Notebooks | Due |\n",
    "| :---: | :---: | :----: | :------ | :----- | :---: |\n",
    "|  8  |  10/21  | 23  | **Numpy:** Data Abstraction, **Numpy:** Multi-dimensional arrays,  | Midterm, 03-01, 03-02 | 10/30 |\n",
    "|  9  |  28  | 30  | **Numpy:** Reading into multi-dimensional arrays, **Pandas:** Dataframes and reading into them;  Merging and matching Dataframes| 03-03, 03-04, 03-05 | 10/30 |\n",
    "|  10  |  11/4  | 6  | **Pandas:** , Series and Views; Wrap Up Unit 3| 03-06, 03-07 | 11/10 |\n",
    "|  11 |  &mdash; | 13   | Classification and Clustering, **Case Study:** Iris Data Set | 04-02, 04-03  | 11/17 |\n",
    "|   |    |    | Notebooks under development&dagger;  | <del>04-04, 04-06, 04-07</del>  |\n",
    "|  12 |  18  | 20  | **Case Study:** [World Happiness Report](https://worldhappiness.report/ed/2019/)  | 04-04, 05-01 | 11/24 |\n",
    "|  13 |  25   | &mdash;  | [Geopandas](http://geopandas.org/), **Case Study:** World Happiness Map | 05-03 | 12/01 |\n",
    "|  14 |  12/2 | 4 |  **Case Study:** Twitter Sentiment Analysis | 05-04 | 12/08 |\n",
    "|  16 |  | 12/13 | **(Take Home) Final Exam**  |\n",
    "\n",
    "&dagger; We will not be covering these notebooks this semester. Feel free to peruse them if interested.\n",
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "* You're probably aware of some parametric prediction methods, e.g., linear regression.  \n",
    "* Let's study a non-parametric prediction method. \n",
    "* The goal of this method: classify something into one of a discrete number of types. \n",
    "* This is also known as 'supervised learning'. \n",
    "\n",
    "# Scikit-Learn\n",
    "\n",
    "* Scikit-Learn is a major machine learning library that includes many reference data sets. \n",
    "* Initial release: June 2007, predates `pandas` but not by much! (Scikit-Learn and `pandas` solved different set of problems so they could simply coexisted for a long time)\n",
    "* It has its own formats. \n",
    "* It's important to know how to translate to other formats to accomplish tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"padding-left:10px; height: 24%; width: 24%;\" src=\"figures/iris_with_labels.jpg\">\n",
    "\n",
    "# The Iris Dataset\n",
    "\n",
    "* There is one dataset that is so well-known that it bears mentioning in any context. \n",
    "* The *iris dataset* consists of a multidimensional array of iris characteristics used in determining species. \n",
    "* Let's explore this dataset and see if we can understand it. \n",
    "* More information on the iris dataset is available at the [Scikit-Learn website](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html).\n",
    "* Scikit-Learn also provides a [Jupyter notebook](plot_iris_dataset.ipynb) included here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _k_-nearest neighbors algorithm\n",
    "\n",
    "* More on the k-NN algorithm: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "For now, suffice it to say that from enough measurements, one can form a prediction \n",
    "from the instances that have been observed so far. This prediction can be accurate or inaccurate \n",
    "based upon the prediction method. \n",
    "\n",
    "<img align=\"right\" style=\"padding-left:10px; height: 40%; width: 40%;\" src=\"figures/datasplit.png\">\n",
    "\n",
    "## Our approach\n",
    "\n",
    "The training samples will be used by the learning algorithms to find the _optimal classification criteria_. The testing set is used only to assess the performance of a fully-trained model, and must remain entirely unseen by the learning algorithm. The test set can be seen as a portion of the dataset which is kept in a \"vault\" until the very end. \n",
    "\n",
    "The Iris Flower dataset is relatively small at exactly 150 samples. Because of this, we will use 130 samples for training, and the remaining 20 for testing.\n",
    "\n",
    "## How kNN works\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px; height: 42%; width: 42%;\" src=\"figures/how_knn_works.png\">\n",
    "\n",
    "The algorithm works as follows:\n",
    "    1. Calculate distance\n",
    "    2. Find closest neighbors\n",
    "    3. Vote for labels\n",
    "\n",
    "How do we measure distance? Depends on the problem domain but Euclidian distance is the most common type. \n",
    "\n",
    "What should _k_ be? It too depends on the problem domain. Imagine a point at where the star is shown. For k = 3, this point would be classified as class B whereas for k = 6 it would be classified as class A!\n",
    "\n",
    "Finally, voting also depends on the problem domain. The normal case is to just count the number. Some variants give more weight to points that are closer.\n",
    "\n",
    "We could vary these parameters to maximize the accuracy of our classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classification Metric</h1>\n",
    "<h2>Confusion Matrix</h2>\n",
    "<p>True = when the prediction agrees with the actual</p>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th><th></th>\n",
    "      <th colspan=\"3\" style=\"text-align:center;\">Prediction</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th scope=\"col\" style=\"text-align:center;\">Setosa</th>\n",
    "      <th style=\"text-align:center;\">Versicolour</th>\n",
    "      <th scope=\"col\" style=\"text-align:center;\">Virginica</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th scope=\"row\"></th>\n",
    "      <td style=\"font-weight:bold\">Setosa</td>\n",
    "      <td>True</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th scope=\"row\">Actual</th>\n",
    "      <td style=\"font-weight:bold\">Versicolour</td>\n",
    "      <td></td>\n",
    "      <td>True</td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th scope=\"row\"></th>\n",
    "      <td style=\"font-weight:bold\">Virginica</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<p>Accuracy = (Number of correctly classified samples) / (Total samples)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a special-purpose format. \n",
    "* A class\n",
    "* Implemented as a dictionary. \n",
    "* Intended for testing machine-learning algorithms. \n",
    "* With fields that make sense for that task.\n",
    "* Most entries are arrays in `numpy` format. \n",
    "\n",
    "Let's find out a bit about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important fields in the iris dataset\n",
    "* `iris.data`: a set of feature vectors describing different plants. \n",
    "* `iris.target`: the kind of plant\n",
    "* `iris.feature_names`: the names of columns\n",
    "* `iris.target_names`: the English names of the kinds. \n",
    "\n",
    "# The classification problem\n",
    "* Given what we know about a thing (`iris.data`) \n",
    "* What species is it (`iris.target`)? \n",
    "\n",
    "# How we approach classification: \n",
    "* Take all data into account. \n",
    "* Think of the data as a function from `data` to `target`.\n",
    "* Approximate that function. \n",
    "\n",
    "# Then, if there is a new kind of iris, \n",
    "* Use the function to predict what species it is. \n",
    "\n",
    "# Let's run the demo provided by scikit-learn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Declare a KNN classifier of a given complexity. The number of neighbors determines runtime.\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# create a map between data and target. \n",
    "knn.fit(iris['data'], iris['target'])\n",
    "\n",
    "# Provide data whose class labels are to be predicted\n",
    "X = [\n",
    "    [5.9, 1.0, 5.1, 1.8],\n",
    "    [3.4, 2.0, 1.1, 4.8],\n",
    "]\n",
    "\n",
    "# Prints the data provided\n",
    "print(X)\n",
    "\n",
    "# Store predicted class labels of X\n",
    "prediction = knn.predict(X)\n",
    "\n",
    "# Prints the predicted class labels of X\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This, according to the predictor, they're both species 1 of 0-2. \n",
    "\n",
    "* Writing such a predictor is a complex task that we study in COMP 135. \n",
    "* You can read up on it here: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "For now, suffice it to say that from enough measurements, one can form a prediction \n",
    "from the instances that have been observed so far. This prediction can be accurate or inaccurate \n",
    "based upon the prediction method. \n",
    "\n",
    "# From whence comes accuracy\n",
    "* You would be right to be suspicious of what I just did. \n",
    "* I didn't tell you anything at all about the prediction method. It is an \"oracle\". \n",
    "* How do we know that this worked? \n",
    "\n",
    "# Cross-validation\n",
    "* Cross-validation is a standard technique in machine learning for testing classifiers. \n",
    "* Separate all feature data into 'training' and 'testing' subsets. \n",
    "* Train on the training subset. \n",
    "* Test on the testing subset. \n",
    "* See if you get the correct answers.\n",
    "\n",
    "# Let's do this. I'll help.\n",
    "* This is a different kind of exercise. \n",
    "* This is a real cross-validation using random data. \n",
    "* There is no one \"correct\" answer. \n",
    "* I can check your answers for sanity but not for correctness. \n",
    "\n",
    "First let's select rows of the data to use as training and testing data. This recipe selects them randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "selections = list(range(len(iris.data)))\n",
    "random.shuffle(selections)\n",
    "training_selections = selections[:130]\n",
    "testing_selections = selections[130:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What this does\n",
    "* `random.shuffle` scrambles the numbers between 0 and 149. \n",
    "* `training_selections` is a list of the array offsets for a training set. \n",
    "* `testing_selections` is a list of the array offsets for a testing set. \n",
    "* These are disjoint lists with no elements in common. \n",
    "* These represent a random sampling of the data in the iris database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_selections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an `array` `training_features` that consists of the rows that match `training_selections`. Look up how to do it. Hint: `iris.data` is an `array`. Use row selection for `np.array`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an `array` `training_targets` that consists of the targets corresponding to the selected training rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the pattern above, train a kNN on the training data. Start with a new one `knn2` and just train on this. Hint: You need the data from parts 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "# Declare a KNN classifier of a given complexity. The number of neighbors determines runtime.\n",
    "import numpy as np\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# create a map between data and target. \n",
    "knn2.fit(training_features, training_targets)\n",
    "knn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Put the test data into an `array` `testing_features`, repeating what you did for training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the predictor as above, but on the array `testing_features`. Put the result into `test_results`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compute the expected outcomes and put them into the `array` `expected_results`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Count the number of identical answers between test_results and expected results and place the result into `correct_answers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer: \n",
    "correct_answers = (test_results == expected_results).sum()\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An afterword on cross-validation\n",
    "* If you got a perfect result, you're lucky. \n",
    "* Classification algorithms aren't perfect. \n",
    "* You can run it again to get an imperfect result. \n",
    "* Running the cross-validation multiple times gives one an idea of how accurate the classifier will be. \n",
    "* There are no \"correct\" answers to this. You just ran a random trial. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
