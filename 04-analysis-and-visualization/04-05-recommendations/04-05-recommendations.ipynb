{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Course Plan 11/20/2019</span>\n",
    "## <span style=\"color:blue\">(Last Updated 11/20/2019)</span>\n",
    "\n",
    "## Updated schedule through the rest of the semester\n",
    "\n",
    "|  Wk   |  M    |  W     | Topic   | Notebooks | Due |\n",
    "| :---: | :---: | :----: | :------ | :----- | :---: |\n",
    "|  8  |  10/21  | 23  | **Numpy:** Data Abstraction, **Numpy:** Multi-dimensional arrays,  | Midterm, 03-01, 03-02 | 10/30 |\n",
    "|  9  |  28  | 30  | **Numpy:** Reading into multi-dimensional arrays, **Pandas:** Dataframes and reading into them;  Merging and matching Dataframes| 03-03, 03-04, 03-05 | 10/30 |\n",
    "|  10  |  11/4  | 6  | **Pandas:** , Series and Views; Wrap Up Unit 3| 03-06, 03-07 | 11/10 |\n",
    "|  11 |  &mdash; | 13   | Classification and Clustering, **Case Study:** Iris Data Set | 04-02, 04-03  | 11/17 |\n",
    "|   |    |    | Notebooks under development&dagger;  | <del>04-04, 04-06, 04-07</del>  |\n",
    "|  12 |  18  | 20  | _k_-means Clustering, **Case Study:** [World Happiness Report](https://worldhappiness.report/ed/2019/), Recommendations  | 04-04, 05-01, 04-05 &Dagger; | 11/24 |\n",
    "|  13 |  25   | &mdash;  | [Geopandas](http://geopandas.org/), **Case Study:** World Happiness Map | 05-03, 05-02 &Dagger; | 12/01 |\n",
    "|  14 |  12/2 | 4 |  **Case Study:** Twitter Sentiment Analysis | 05-04 | 12/08 |\n",
    "|  16 |  | 12/13 | **(Take Home) Final Exam**  |\n",
    "\n",
    "&dagger; We will not be covering these notebooks this semester. Feel free to peruse them if interested.\n",
    "\n",
    "&Dagger; As time permits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"padding-left:10px; height: 60%; width: 60%\" src=\"figures/use_cases.jpg\" >\n",
    "\n",
    "# Recommendations\n",
    "\n",
    "Recommendations systems have taken on an important role in Data Science \n",
    "\n",
    "### Movie Suggestion:\n",
    "\n",
    "We will start this example off by comparing different movies, then recommending similar ones. First, import a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "movies = pd.read_csv('MoviesList.csv',header = 0) \n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what the columns are. Since we don't need all of them, we can make a new dataframe with just the ones that we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using _Rating_ and the two _Genre_ columns to come up with recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_attrs = DataFrame(movies, columns = ['Movie ID:', 'Name:','Genre:','Rating:','Additional Genre:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when \"Additional Genre:\" is blank...\n",
    "movie_attrs.loc[(movie_attrs['Additional Genre:'].isna()), 'Additional Genre:'] = ''\n",
    "# movie_attrs[40:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fave_movie = 5 # The index of the user's favorite movie (Titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combos_no_dups(left, right):\n",
    "    combos = left.assign(key=1).merge(right.assign(key=1), on='key').drop('key', 1)\n",
    "    combos = combos[ (combos['Movie ID:_x'] != combos[\"Movie ID:_y\"]) ]\n",
    "    return combos\n",
    "\n",
    "movie_attrs.apply((lambda x: (x['Name:'], x['Genre:'], x['Additional Genre:'], x['Rating:'])), axis=1)\n",
    "\n",
    "combos = combos_no_dups(movie_attrs[fave_movie:fave_movie+1], movie_attrs[:])\n",
    "#combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Similarity\n",
    "\n",
    "<div>\n",
    "    <img align=\"right\" style=\"padding-left:10px; height: 20%; width: 20%\" src=\"figures/jaccard_union.png\" >\n",
    "</div><div>\n",
    "    <img align=\"right\" style=\"padding-left:10px; height: 20%; width: 20%\" src=\"figures/jaccard_intersection.png\" >\n",
    "</div><div>\n",
    "    <br /><img align=\"left\" style=\"padding-right:10px; height: 40%; width: 40%\" src=\"figures/jaccard_equation.png\" >\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Similarity Implementation:\n",
    "\n",
    "The implementation of the similarity function is based on Python `sets`, the only catch being that `Additional Genre` can sometimes be blank, throwing off the calculation for those situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    set1_ = set(filter(None, list1)) # remove any blanks\n",
    "    set2_ = set(filter(None, list2))\n",
    "    intersection = set1_ & set2_\n",
    "    union = set1_ | set2_\n",
    "    similarity = float(len(intersection) / len(union))\n",
    "    return float(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(row):\n",
    "    list1 = [row['Genre:_x'], row['Rating:_x'], row['Additional Genre:_x']]\n",
    "    list2 = [row['Genre:_y'], row['Rating:_y'], row['Additional Genre:_y']]\n",
    "    return jaccard_similarity(list1, list2)\n",
    "\n",
    "combos['similarity'] = combos.apply(similarity, axis=1)\n",
    "\n",
    "drop_columns = ['Movie ID:_x', 'Name:_x', 'Genre:_x', 'Rating:_x',\n",
    "                'Additional Genre:_x', 'Movie ID:_y', 'Genre:_y', 'Rating:_y', 'Additional Genre:_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('If you liked {}, you might also enjoy'.format(list(movie_attrs[fave_movie:fave_movie+1]['Name:'])[0]))\n",
    "\n",
    "# Set the threshold to 0.22 to verify that we caught cases where Additional Genre was blank.\n",
    "\n",
    "combos[combos['similarity'] > 0.22].drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The wrong approach \n",
    "\n",
    "If you are coming from a traditional programming language background, you may be tempted to write code with loops in it, as shown below. _Do not yield to this temptation!_ \n",
    "The point of libraries like numpy and pandas is to exploit the parallelism inherent in `ndarray`s and `dataframe`s. Both libraries take advantage of optimizations that your \"loopy\" code can not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid this type of coding:\n",
    "\n",
    "# def movie_suggestion(movie_id):\n",
    "#     num_movies = len(movie_attrs)\n",
    "#     print('If you liked: ' + movie_attrs.iloc[movie_id-1]['Name:'] + '\\n')\n",
    "#     print('Similar movies that you would like are:\\n')\n",
    "#     l1 = [movie_attrs.iloc[movie_id-1]['Genre:'],movie_attrs.iloc[movie_id - 1]['Additional Genre:'],movie_attrs.iloc[movie_id - 1]['Rating:']]\n",
    "#     for counter in range(0,num_movies):\n",
    "#         l2 = [movie_attrs.iloc[counter]['Genre:'],movie_attrs.iloc[counter]['Additional Genre:'],movie_attrs.iloc[counter]['Rating:']]\n",
    "#         x = jaccard_similarity(l1,l2) \n",
    "#         if (x > .22):\n",
    "#             if (counter != movie_id - 1):\n",
    "#                 print(movie_attrs.iloc[counter]['Name:'], x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\"><img align=\"right\" style=\"padding-left:10px; height: 40%; width: 40%\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/52/Collaborative_filtering.gif\" ></a>\n",
    "\n",
    "The above example is an example of **Collaborative filtering**, a kind of recommendation system. This type of recommendation system makes predictions of what might interest a person based on the taste of many other users. It assumes that if person X likes Snickers, and person Y likes Snickers and Milky Way, then person X might like Milky Way as well. This version of collaborative filtering is close to clustering &mdash; the recommendations are points in hyperspace that are close to the initial points.\n",
    "\n",
    "A generalized version of Collaborative filtering, implied by the image above, is a three-step process:\n",
    "\n",
    "1. A user expresses their preferences by rating items (e.g. books, movies or CDs) of the system. These ratings can be viewed as an approximate representation of the user's interest in the corresponding domain.\n",
    "2. The system matches this user's ratings against other users' and finds the people with most \"similar\" tastes.\n",
    "3. With similar users, the system recommends items that the similar users have rated highly but not yet being rated by this user (presumably the absence of rating is often considered as the unfamiliarity of an item)\n",
    "\n",
    "A key problem of collaborative filtering is how to combine and weight the preferences of user neighbors. Sometimes, users can immediately rate the recommended items. As a result, the system gains an increasingly accurate representation of user preferences over time.\n",
    "\n",
    "Recommendation systems based on **Content-based filtering** focus on the products themselves and recommends other products that have similar attributes. Content-based filtering relies on the characteristics of the products themselves, not on _other_ users to interact with the products before making a recommendation.\n",
    "\n",
    "Experience has shown <a href=\"https://en.wikipedia.org/wiki/Recommender_system#Hybrid_recommender_systems\"><strong>Hybrid Recommendation Systems</strong></a> to be the most effective but they are the most expensive to build and/or deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more extensive dataset\n",
    "\n",
    "Collaborative datasets for movies (and other products) can be large! Here is a [small (1 MB) subset of the IMDB database](https://grouplens.org/datasets/movielens/latest/), downloaded and unzipped for your convenience.\n",
    "\n",
    "I'm not sure if our servers can accommodate everyone working with the dataset simultaneously but it's worth trying. \n",
    "\n",
    "The above-referenced page also links to the _full_ version of the dataset (265MB, zipped). We will **not** be using that dataset in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-latest-small/movies.csv',header = 0) \n",
    "\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-latest-small/ratings.csv',header = 0) \n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to interpret the [timestamp](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html) thus:\n",
    "```\n",
    "    >>> pd.Timestamp(1493846415, unit='s')\n",
    "    Timestamp('2017-05-03 21:20:15')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be covering the topic of movie selection further in **05-02-movie-suggestion**, time permitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
